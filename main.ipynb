{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "사진에 있는 선반과 물체들을 감지하는 기능\n",
    "ㄴ 선반을 사직으로 찍게 할건지 선반의 종류를 사용자가 선택하게 할건지\n",
    "감지된 물체중에 사격형이 아닌 물체를 사각화 시켜주는 기능\n",
    "\n",
    "사각화 된 물체를 종류에 맞게 분리해주는 기능\n",
    "\n",
    "분리된 물체를 선반에 맞춰 정리해주는기능\n",
    "\n",
    "정리된 모습의 물체화 선반을 단말기에 출력하는 기능\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 l:\\2024-1\\SW\\0429   \\Arrangement_of_Jinn_Dolsoe\\1.jpg: 480x640 4 bottles, 1 cup, 547.2ms\n",
      "Speed: 2.0ms preprocess, 547.2ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "from ultralytics.engine.results import Results\n",
    "\n",
    "# Load a pretrained YOLOv8n model\n",
    "model = YOLO('yolov8x-seg.pt')\n",
    "\n",
    "# Run inference on an image\n",
    "results: Results = model('예제선반1.jpg')  # results list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "class YoloObject:\n",
    "    def __init__(self, object, xyxy, conf):\n",
    "        self.object = object\n",
    "        self.xyxy = xyxy\n",
    "        self.conf = conf\n",
    "\n",
    "    def show(self):\n",
    "        print(f\"xyxy: {self.xyxy}\")\n",
    "        print(f\"conf: {self.conf}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[422.8280, 531.7388, 534.7506, 853.8667]])\n",
      "tensor([[604.0400, 408.5475, 729.7561, 839.8859]])\n",
      "tensor([[331.1500, 664.9312, 441.1597, 837.7330]])\n",
      "tensor([[509.1806, 346.8644, 647.1357, 806.8654]])\n",
      "tensor([[247.2962, 643.5244, 301.4925, 842.6123]])\n"
     ]
    }
   ],
   "source": [
    "for r in results[0]:\n",
    "    print(r.boxes.xyxy)\n",
    "\n",
    "import cv2\n",
    "\n",
    "# Global variables\n",
    "drawing = False # true if mouse is pressed\n",
    "ix, iy = -1, -1\n",
    "img = None\n",
    "temp_img = None\n",
    "\n",
    "# Mouse callback function\n",
    "def draw_rectangle(event, x, y, flags, param):\n",
    "    global ix, iy, drawing, img, temp_img\n",
    "\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        drawing = True\n",
    "        ix, iy = x, y\n",
    "        temp_img = img.copy()\n",
    "\n",
    "    elif event == cv2.EVENT_MOUSEMOVE:\n",
    "        if drawing is True:\n",
    "            img = temp_img.copy()\n",
    "            cv2.rectangle(img, (ix, iy), (x, y), (0, 255, 0), 1)\n",
    "\n",
    "    elif event == cv2.EVENT_LBUTTONUP:\n",
    "        drawing = False\n",
    "        cv2.rectangle(img, (ix, iy), (x, y), (0, 255, 0), -1)\n",
    "\n",
    "# Load an image\n",
    "img = results[0].orig_img.copy()\n",
    "cv2.namedWindow('image')\n",
    "cv2.setMouseCallback('image', draw_rectangle)\n",
    "\n",
    "while(1):\n",
    "    # # Define the new resolution\n",
    "    # new_width = 800\n",
    "    # new_height = 600\n",
    "\n",
    "    # # Resize the image\n",
    "    # resized_image = cv2.resize(img, (new_width, new_height))\n",
    "    # cv2.imshow('image', resized_image)\n",
    "    cv2.imshow('image', img)\n",
    "    if cv2.waitKey(1) & 0xFF == 27:  # exit if ESC is pressed\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[        342,         672],\n",
      "       [        340,         674],\n",
      "       [        338,         674],\n",
      "       [        338,         678],\n",
      "       [        336,         680],\n",
      "       [        336,         826],\n",
      "       [        340,         830],\n",
      "       [        346,         830],\n",
      "       [        348,         832],\n",
      "       [        352,         832],\n",
      "       [        354,         834],\n",
      "       [        358,         834],\n",
      "       [        360,         836],\n",
      "       [        368,         836],\n",
      "       [        370,         838],\n",
      "       [        406,         838],\n",
      "       [        408,         836],\n",
      "       [        412,         836],\n",
      "       [        414,         834],\n",
      "       [        414,         832],\n",
      "       [        422,         824],\n",
      "       [        422,         822],\n",
      "       [        424,         820],\n",
      "       [        424,         816],\n",
      "       [        426,         814],\n",
      "       [        426,         812],\n",
      "       [        428,         810],\n",
      "       [        428,         808],\n",
      "       [        430,         806],\n",
      "       [        430,         794],\n",
      "       [        432,         792],\n",
      "       [        432,         776],\n",
      "       [        434,         774],\n",
      "       [        434,         766],\n",
      "       [        436,         764],\n",
      "       [        436,         750],\n",
      "       [        438,         748],\n",
      "       [        438,         702],\n",
      "       [        440,         700],\n",
      "       [        440,         684],\n",
      "       [        442,         682],\n",
      "       [        442,         676],\n",
      "       [        440,         674],\n",
      "       [        438,         674],\n",
      "       [        436,         672]], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "boxes = list()\n",
    "\n",
    "# View results\n",
    "for r in results[0]:\n",
    "    boxes.append(YoloObject(r, r.boxes.xyxy, r.boxes.conf))\n",
    "    # print(r.boxes)  # print the Boxes object containing the detection bounding boxes\n",
    "    # print(r.boxes.xyxy)  # print the xyxy tensor of bounding boxes\n",
    "    # print(r.boxes.conf)  # print the confidence tensor of bounding boxes\n",
    "\n",
    "results[0].show()\n",
    "# boxes[7].show()\n",
    "boxes[2].object.show()\n",
    "print(boxes[2].object.masks.xy)\n",
    "\n",
    "arr = boxes[2].object.masks.xy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "imread로 원래 있던 그림을 기본으로 하고 float32형 array배열의 arr안에 있는 데이터를 점으로 cv2로 찍고싶어"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[        342         672]\n",
      "[        340         674]\n",
      "[        338         674]\n",
      "[        338         678]\n",
      "[        336         680]\n",
      "[        336         826]\n",
      "[        340         830]\n",
      "[        346         830]\n",
      "[        348         832]\n",
      "[        352         832]\n",
      "[        354         834]\n",
      "[        358         834]\n",
      "[        360         836]\n",
      "[        368         836]\n",
      "[        370         838]\n",
      "[        406         838]\n",
      "[        408         836]\n",
      "[        412         836]\n",
      "[        414         834]\n",
      "[        414         832]\n",
      "[        422         824]\n",
      "[        422         822]\n",
      "[        424         820]\n",
      "[        424         816]\n",
      "[        426         814]\n",
      "[        426         812]\n",
      "[        428         810]\n",
      "[        428         808]\n",
      "[        430         806]\n",
      "[        430         794]\n",
      "[        432         792]\n",
      "[        432         776]\n",
      "[        434         774]\n",
      "[        434         766]\n",
      "[        436         764]\n",
      "[        436         750]\n",
      "[        438         748]\n",
      "[        438         702]\n",
      "[        440         700]\n",
      "[        440         684]\n",
      "[        442         682]\n",
      "[        442         676]\n",
      "[        440         674]\n",
      "[        438         674]\n",
      "[        436         672]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "# Read the original image using imread\n",
    "image = cv2.imread(\"예제선반1.jpg\")\n",
    "\n",
    "# Iterate over the data points in arr and draw them as points on the image\n",
    "for point in arr[0]:\n",
    "    print(point)\n",
    "    x, y = point\n",
    "    cv2.circle(image, (int(x), int(y)), radius=2, color=(0, 0, 255), thickness=-1)\n",
    "\n",
    "# Display the image with the plotted points\n",
    "cv2.imshow(\"Image with Points\", image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "각각 object들의 좌표를 인식하고 물건이 배치되어있는 이미지 형태로 출력할 수 있게 해줘"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Shelf:\n",
    "    def __init__(self, xyxy):\n",
    "        self.xyxy = xyxy\n",
    "        self.objects = []\n",
    "\n",
    "    def add_object(self, obj):\n",
    "        self.objects.append(obj)\n",
    "\n",
    "    def remove_object(self, obj):\n",
    "        self.objects.remove(obj)\n",
    "\n",
    "    def display_objects(self):\n",
    "        for obj in self.objects:\n",
    "            print(obj)\n",
    "\n",
    "    def clear_shelf(self):\n",
    "        self.objects = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected Object 1 width: 112, height: 322\n",
      "Detected Object 2 width: 125, height: 431\n",
      "Detected Object 3 width: 110, height: 173\n",
      "Detected Object 4 width: 138, height: 460\n",
      "Detected Object 5 width: 54, height: 199\n"
     ]
    }
   ],
   "source": [
    "image_path = '예제선반1.jpg'\n",
    "image = cv2.imread(image_path)\n",
    "\n",
    "# max_width = 500 # 최대 이미지 설정\n",
    "# max_height = 500\n",
    "\n",
    "for r in results:\n",
    "    for idx, box in enumerate(r.boxes.xyxy):\n",
    "        x1, y1, x2, y2 = map(int, box[:4])  # 경계 상자 좌표 (정수로 변환)\n",
    "        cropped_img = image[y1:y2, x1:x2]  # 경계 상자 좌표를 사용하여 이미지 자르기\n",
    "\n",
    "        height, width = cropped_img.shape[:2]\n",
    "\n",
    "        # if width > max_width or height > max_height: # 이미지가 너무 크게 나와서 조절하는용도\n",
    "        #     scaling_factor = min(max_width / width, max_height / height)\n",
    "        # new_width = int(width * scaling_factor)\n",
    "        new_width = int(width)\n",
    "        # new_height = int(height * scaling_factor)\n",
    "        new_height = int(height)\n",
    "        cropped_img = cv2.resize(cropped_img, (new_width, new_height))\n",
    "            \n",
    "        print(f'Detected Object {idx+1} width: {new_width}, height: {new_height}')  # 객체의 가로와 세로 길이 출력\n",
    "        cv2.imshow(f'Detected Object {idx+1}', cropped_img)\n",
    "        cv2.waitKey(0)\n",
    "\n",
    "cv2.destroyAllWindows() # 이미지창 닫기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "물건의 가로와 세로 픽셀 길이로 선반에 들어가는지 가용성을 체크한다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
